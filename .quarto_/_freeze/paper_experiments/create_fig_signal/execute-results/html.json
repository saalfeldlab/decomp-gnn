{
  "hash": "7db0c39ab0fe457c4d8846ae2871c1f3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Training GNN on signaling\nauthor: CÃ©dric Allier, Michael Innerberger, Stephan Saalfeld\ncategories:\n  - Particles\nexecute:\n  echo: false\nimage: \"create_fig_signal_files/figure-html/cell-4-output-1.png\"\n---\n\n\n\n\nThis script generates figures shown in Supplementary Figures 18.\nA GNN is trained on a signaling network (998 nodes, 17,865 edges).\nNote 100 of datasets are generated for training.\n\n\n\nFirst, we load the configuration file and set the device.\n\n::: {#8dfcf3fc .cell execution_count=2}\n``` {.python .cell-code}\nconfig_file = 'signal_N_100_2'\nfigure_id = 'supp18'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n```\n:::\n\n\nThe following model is used to simulate the signaling network with PyTorch Geometric.\n\n::: {#460ecfb4 .cell execution_count=3}\n``` {.python .cell-code}\nclass SignalingNetwork(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n\n    Returns\n    -------\n    pred : float\n\n    \"\"\"\n\n    def __init__(self, aggr_type=[], p=[], bc_dpos=[]):\n        super(SignalingNetwork, self).__init__(aggr=aggr_type)\n\n        self.p = p\n        self.bc_dpos = bc_dpos\n\n    def forward(self, data=[], return_all=False):\n        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = x[:, 5].long()\n        parameters = self.p[particle_type]\n        b = parameters[:, 0:1]\n        c = parameters[:, 1:2]\n\n        u = x[:, 6:7]\n\n        msg = self.propagate(edge_index, u=u, edge_attr=edge_attr)\n\n        du = -b * u + c * torch.tanh(u) + msg\n\n        if return_all:\n            return du, -b * u + c * torch.tanh(u), msg\n        else:\n            return du\n\n    def message(self, u_j, edge_attr):\n\n        self.activation = torch.tanh(u_j)\n        self.u_j = u_j\n\n        return edge_attr[:, None] * torch.tanh(u_j)\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n```\n:::\n\n\nThe data is generated with the above Pytorch Geometric model.\nIf the simulation is too large, you can decrease n_particles (multiple of 2) and n_nodes in \"signal_N_100_2.yaml\"\n\n::: {#6169a541 .cell execution_count=4}\n``` {.python .cell-code}\np = torch.squeeze(torch.tensor(config.simulation.params))\nmodel = SignalingNetwork(aggr_type=config.graph_model.aggr_type, p=torch.squeeze(p), bc_dpos=bc_dpos)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='7', run=0, step=10, save_velocity=True)\n\ndata_generate_synaptic(config, model, **generate_kwargs)\n```\n:::\n\n\nFinally, we generate the figures that are shown in Figure 2.\nThe frames of the first six datasets are saved in 'decomp-gnn/paper_experiments/graphs_data/graphs_signal_N_100_2/Fig/'.\n\n\n::: {#86660970 .cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![Initial configuration of the simulation. There are 998 nodes. The colors indicate the node scalar values.](create_fig_signal_files/figure-html/cell-7-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#3be0caa6 .cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![Frame 300 out of 1000](create_fig_signal_files/figure-html/cell-8-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#6e40a8f5 .cell execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![Frame 600 out of 1000](create_fig_signal_files/figure-html/cell-9-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#b3fa7e9b .cell execution_count=9}\n\n::: {.cell-output .cell-output-display}\n![Frame 900 out of 1000](create_fig_signal_files/figure-html/cell-10-output-1.png){width=451 height=451}\n:::\n:::\n\n\nThe GNN model (see src/ParticleGraph/models/Signal_Propagation.py) is trained and tested.\n\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\n::: {#6640e25d .cell execution_count=10}\n``` {.python .cell-code}\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n```\n:::\n\n\nDuring training the plot of the embedding are saved in\n\"paper_experiments/log/try_signal_N_100_2/tmp_training/embedding\"\nThe plot of the pairwise interactions are saved in\n\"paper_experiments/log/try_signal_N_100_2/tmp_training/function\"\n\nThe model that has been trained in the previous step is used to generate the rollouts.\n\n::: {#fad6b05c .cell execution_count=11}\n``` {.python .cell-code}\ndata_test(config, config_file, **test_kwargs)\n```\n:::\n\n\n::: {#42ef05b8 .cell execution_count=12}\n\n::: {.cell-output .cell-output-display}\n![Frame 0 out of 1000](create_fig_signal_files/figure-html/cell-13-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#a158be81 .cell execution_count=13}\n\n::: {.cell-output .cell-output-display}\n![Frame 250 out of 1000](create_fig_signal_files/figure-html/cell-14-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#54aea2fc .cell execution_count=14}\n\n::: {.cell-output .cell-output-display}\n![Frame 500 out of 1000](create_fig_signal_files/figure-html/cell-15-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#e1b9fc02 .cell execution_count=15}\n\n::: {.cell-output .cell-output-display}\n![Frame 750 out of 1000](create_fig_signal_files/figure-html/cell-16-output-1.png){width=451 height=451}\n:::\n:::\n\n\nFinally, we generate figures from the post-analysis of the GNN.\nThe results of the GNN post-analysis are saved into 'decomp-gnn/paper_experiments/log/try_signal_N_100_2/results'.\n\n::: {#9f3949bb .cell execution_count=16}\n``` {.python .cell-code}\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n```\n:::\n\n\n::: {#4f1c1c5a .cell execution_count=17}\n\n::: {.cell-output .cell-output-display}\n![Comparison between the learned and the true connectivity matrix values](create_fig_signal_files/figure-html/cell-18-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#02dc0b35 .cell execution_count=18}\n\n::: {.cell-output .cell-output-display}\n![Comparison between the learned and the true transfert functions](create_fig_signal_files/figure-html/cell-19-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#f4e4c1c0 .cell execution_count=19}\n\n::: {.cell-output .cell-output-display}\n![Comparison between the learned and the true update functions (neuron type 1)](create_fig_signal_files/figure-html/cell-20-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#868033b6 .cell execution_count=20}\n\n::: {.cell-output .cell-output-display}\n![Comparison between the learned and the true update functions (neuron type 2)](create_fig_signal_files/figure-html/cell-21-output-1.png){width=451 height=451}\n:::\n:::\n\n\n",
    "supporting": [
      "create_fig_signal_files"
    ],
    "filters": [],
    "includes": {}
  }
}