{
  "hash": "3e7056714817611fac74e0d0598b5124",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Gravity-like system with system with different particle masses\nauthor: CÃ©dric Allier, Michael Innerberger, Stephan Saalfeld\ncategories:\n  - Particles\nexecute:\n  echo: false\nimage: \"create_fig_2_2_files/figure-html/cell-10-output-1.png\"\n---\n\n\n\n\nThis script creates the second column of paper's Figure 2.\nSimulation of a gravity-like system, 960 particles, 16 different masses.\n\n\n\nFirst, we load the configuration file and set the device.\n\n::: {#9008256f .cell execution_count=2}\n``` {.python .cell-code}\nconfig_file = 'gravity_16'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n```\n:::\n\n\nThe following model is used to simulate the gravity-like system with PyTorch Geometric.\n\n::: {#2ba655fb .cell execution_count=3}\n``` {.python .cell-code}\nclass GravityModel(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the acceleration of particles as a function of their relative position according to the gravity law.\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n\n    Returns\n    -------\n    pred : float\n        the acceleration of the particles (dimension 2)\n    \"\"\"\n\n    def __init__(self, aggr_type=[], p=[], clamp=[], pred_limit=[], bc_dpos=[]):\n        super(GravityModel, self).__init__(aggr='add')  # \"mean\" aggregation.\n\n        self.p = p\n        self.clamp = clamp\n        self.pred_limit = pred_limit\n        self.bc_dpos = bc_dpos\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 5])\n\n        mass = self.p[particle_type]\n        dd_pos = self.propagate(edge_index, pos=x[:, 1:3], mass=mass[:, None])\n        return dd_pos\n\n    def message(self, pos_i, pos_j, mass_j):\n        distance_ij = torch.sqrt(torch.sum(self.bc_dpos(pos_j - pos_i) ** 2, axis=1))\n        distance_ij = torch.clamp(distance_ij, min=self.clamp)\n        direction_ij = self.bc_dpos(pos_j - pos_i) / distance_ij[:, None]\n        dd_pos = mass_j * direction_ij / (distance_ij[:, None] ** 2)\n\n        return torch.clamp(dd_pos, max=self.pred_limit)\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n```\n:::\n\n\nThe data is generated with the above Pytorch Geometric model.\nNote two datasets are generated, one for training and one for validation.\nIf the simulation is too large, you can decrease n_particles (multiple of 16) in \"gravity_16.yaml\".\n\n::: {#1b6a7896 .cell execution_count=4}\n``` {.python .cell-code}\np = torch.squeeze(torch.tensor(config.simulation.params))\nmodel = GravityModel(aggr_type=config.graph_model.aggr_type, p=torch.squeeze(p), clamp=config.training.clamp,\n              pred_limit=config.training.pred_limit, bc_dpos=bc_dpos)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n```\n:::\n\n\nFinally, we generate the figures that are shown in Figure 2.\nAll frames are saved in 'decomp-gnn/paper_experiments/graphs_data/gravity_16/Fig/'.\n\n\n::: {#8464f1af .cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![Initial configuration of the simulation. There are 960 particles. The colors indicate different masses.](create_fig_2_2_files/figure-html/cell-7-output-1.png){width=470 height=470}\n:::\n:::\n\n\n::: {#ec479d1c .cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![Frame 600 out of 2000](create_fig_2_2_files/figure-html/cell-8-output-1.png){width=470 height=470}\n:::\n:::\n\n\n::: {#4ca9c19a .cell execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![Frame 1200 out of 2000](create_fig_2_2_files/figure-html/cell-9-output-1.png){width=470 height=470}\n:::\n:::\n\n\n::: {#894314a2 .cell execution_count=9}\n\n::: {.cell-output .cell-output-display}\n![Frame 1800 out of 2000](create_fig_2_2_files/figure-html/cell-10-output-1.png){width=470 height=470}\n:::\n:::\n\n\n",
    "supporting": [
      "create_fig_2_2_files"
    ],
    "filters": [],
    "includes": {}
  }
}