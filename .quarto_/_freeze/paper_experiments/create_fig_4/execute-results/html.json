{
  "hash": "f2488655fdae7fdc7cc66947f91b7122",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Training GNN on attraction-repulsion (hidden field)\nauthor: CÃ©dric Allier, Michael Innerberger, Stephan Saalfeld\ncategories:\n  - Particles\nexecute:\n  echo: false\nimage: \"create_fig_4_files/figure-html/cell-4-output-1.png\"\n---\n\n\n\n\nThis script creates figure of paper's Figure 4.\nA GNN learns the motion rules of an attraction-repulsion system.\nThe simulation used to train the GNN consists of 4800 particles of three different types.\nThe particles interact with each other according to three different attraction-repulsion laws.\nThe particle interact also with a hidden dynamical field.\n\n\n\nFirst, we load the configuration file and set the device.\n\n::: {#974c2e07 .cell execution_count=2}\n``` {.python .cell-code}\nconfig_file = 'arbitrary_3_field_video'\nfigure_id = '4'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n```\n:::\n\n\nThe following model is used to simulate the attraction-repulsion system with PyTorch Geometric.\n\n::: {#2d683ba5 .cell execution_count=3}\n``` {.python .cell-code}\nclass ParticleField(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the speed of particles as a function of their relative position according to an attraction-repulsion law.\n    The latter is defined by four parameters p = (p1, p2, p3, p4) and a parameter sigma.\n\n    See https://github.com/gpeyre/numerical-tours/blob/master/python/ml_10_particle_system.ipynb\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n\n    Returns\n    -------\n    pred : float\n        the speed of the particles (dimension 2)\n    \"\"\"\n\n    def __init__(self, aggr_type=[], p=[], sigma=[], bc_dpos=[], dimension=2):\n        super(ParticleField, self).__init__(aggr=aggr_type)  # \"mean\" aggregation.\n\n        self.p = p\n        self.sigma = sigma\n        self.bc_dpos = bc_dpos\n        self.dimension = dimension\n\n    def forward(self, data=[], has_field=False):\n        x, edge_index = data.x, data.edge_index\n\n        if has_field:\n            field = x[:,6:7]\n        else:\n            field = torch.ones_like(x[:,0:1])\n\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 1 + 2*self.dimension])\n        parameters = self.p[particle_type,:]\n        d_pos = self.propagate(edge_index, pos=x[:, 1:self.dimension+1], parameters=parameters, field=field)\n        return d_pos\n\n\n    def message(self, pos_i, pos_j, parameters_i, field_j):\n\n        distance_squared = torch.sum(self.bc_dpos(pos_j - pos_i) ** 2, axis=1)  # squared distance\n        f = (parameters_i[:, 0] * torch.exp(-distance_squared ** parameters_i[:, 1] / (2 * self.sigma ** 2))\n               - parameters_i[:, 2] * torch.exp(-distance_squared ** parameters_i[:, 3] / (2 * self.sigma ** 2)))\n        d_pos = f[:, None] * self.bc_dpos(pos_j - pos_i) * field_j\n\n        return d_pos\n\n    def psi(self, r, p):\n        return r * (p[0] * torch.exp(-r ** (2 * p[1]) / (2 * self.sigma ** 2))\n                    - p[2] * torch.exp(-r ** (2 * p[3]) / (2 * self.sigma ** 2)))\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n```\n:::\n\n\nThe training data is generated with the above Pytorch Geometric model\n\nVizualizations of the particle motions can be found in \"decomp-gnn/paper_experiments/graphs_data/graphs_arbitrary_3_field_video/\"\n\nIf the simulation is too large, you can decrease n_particles (multiple of 3) and n_nodes  in \"arbitrary_3_field_video.yaml\"\n\n::: {#cd995a50 .cell execution_count=4}\n``` {.python .cell-code}\np = torch.squeeze(torch.tensor(config.simulation.params))\nsigma = config.simulation.sigma\nmodel = ParticleField(\n    aggr_type=config.graph_model.aggr_type,\n    p=p,\n    sigma=sigma,\n    bc_dpos=bc_dpos,\n    dimension=config.simulation.dimension\n)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=20)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=20, save_velocity=True)\n\ndata_generate_particle_field(config, model, bc_pos, bc_dpos, **generate_kwargs)\n```\n:::\n\n\n::: {#7c442568 .cell execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![Frame 100. The orange, blue, and green particles represent the three different particle types.](create_fig_4_files/figure-html/cell-6-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#e1a04290 .cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![Frame 100. The arrows shows the influence of the hidden field on the particles velocity field.](create_fig_4_files/figure-html/cell-7-output-1.png){width=451 height=451}\n:::\n:::\n\n\nThe GNN model (see src/ParticleGraph/models/Interaction_Particle.py) is trained and tested.\n\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nDuring training the plots of the embedding are saved in\n\"paper_experiments/log/try_arbitrary_3_field_video/tmp_training/embedding\".\nThe plots of the interaction functions are saved in \"function\" and the hidden field in \"field\".\n\n::: {#259bea65 .cell execution_count=7}\n``` {.python .cell-code}\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n```\n:::\n\n\nThe model that has been trained in the previous step is used to generate the rollouts.\n\n::: {#3fca5805 .cell execution_count=8}\n``` {.python .cell-code}\ndata_test(config, config_file, **test_kwargs)\n```\n:::\n\n\nFinally, we generate the figures that are shown in Figure 4.\nThe results of the GNN post-analysis are saved into 'decomp-gnn/paper_experiments/log/try_arbitrary_3_field_video/results'.\n\n::: {#589ce953 .cell execution_count=9}\n``` {.python .cell-code}\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n```\n:::\n\n\n::: {#9ce0f75d .cell execution_count=10}\n\n::: {.cell-output .cell-output-display}\n![Learned latent vectors (x4800)](create_fig_4_files/figure-html/cell-11-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#741cf226 .cell execution_count=11}\n\n::: {.cell-output .cell-output-display}\n![Learned interaction functions (x3)](create_fig_4_files/figure-html/cell-12-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#03952b2d .cell execution_count=12}\n\n::: {.cell-output .cell-output-display}\n![UMAP projection of the learned interaction functions (x3)](create_fig_4_files/figure-html/cell-13-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#b0d18e62 .cell execution_count=13}\n\n::: {.cell-output .cell-output-display}\n![GNN rollout inference at frame 100](create_fig_4_files/figure-html/cell-14-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#ae54cb20 .cell execution_count=14}\n\n::: {.cell-output .cell-output-display}\n![Reconstructed field at frame 100](create_fig_4_files/figure-html/cell-15-output-1.png){width=451 height=451}\n:::\n:::\n\n\n::: {#3fc430f7 .cell execution_count=15}\n\n::: {.cell-output .cell-output-display}\n![Comparison betwween true and learned hidden field values](create_fig_4_files/figure-html/cell-16-output-1.png){width=451 height=451}\n:::\n:::\n\n\nAll frames can be found in \"decomp-gnn/paper_experiments/log/try_arbitrary_3_field_video/tmp_recons/\"\n\n\n",
    "supporting": [
      "create_fig_4_files"
    ],
    "filters": [],
    "includes": {}
  }
}