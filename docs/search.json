[
  {
    "objectID": "paper_experiments/create_fig_3_2.html",
    "href": "paper_experiments/create_fig_3_2.html",
    "title": "Training GNN on attraction-repulsion (asymmetric, 3 particle types)",
    "section": "",
    "text": "This script creates the second column of paper’s Figure 3. A GNN learns the motion rules of an asymmetric attraction-repulsion system The simulation used to train the GNN consists of 4800 particles of three different types. The particles interact with each other according to 9 different attraction-repulsion laws. The interaction functions asymmetrically depend on the types of both particles.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'arbitrary_3_3'\nfigure_id = '3_2'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the attraction-repulsion system with PyTorch Geometric.\n\nclass AttractionRepulsionModel(pyg.nn.MessagePassing):\n    \"\"\"\n    Compute the speed of particles as a function of their relative position according to an attraction-repulsion law.\n    The latter is defined by four parameters p = (p1, p2, p3, p4) and a parameter sigma.\n\n    See https://github.com/gpeyre/numerical-tours/blob/master/python/ml_10_particle_system.ipynb\n    \"\"\"\n\n    def __init__(self, p=[], sigma=[], bc_dpos=[]):\n        super(AttractionRepulsionModel, self).__init__(aggr='mean')  # \"mean\" aggregation.\n\n        self.p = p\n        self.sigma = sigma\n        self.bc_dpos = bc_dpos\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = x[:, 5:6]\n        d_pos = self.propagate(edge_index, pos=x[:, 1:3], particle_type=particle_type)\n        return d_pos\n\n    def message(self, pos_i, pos_j, particle_type_i, particle_type_j):\n        distance_squared = torch.sum(self.bc_dpos(pos_j - pos_i) ** 2, axis=1)  # squared distance\n        parameters = self.p[to_numpy(particle_type_i), to_numpy(particle_type_j), :].squeeze()\n\n        psi = (parameters[:, 0] * torch.exp(-distance_squared ** parameters[:, 1] / (2 * self.sigma ** 2))\n               - parameters[:, 2] * torch.exp(-distance_squared ** parameters[:, 3] / (2 * self.sigma ** 2)))\n        d_pos = psi[:, None] * self.bc_dpos(pos_j - pos_i)\n        return d_pos\n\n    def psi(self, r, p):\n        return r * (p[0] * torch.exp(-r ** (2 * p[1]) / (2 * self.sigma ** 2))\n                    - p[2] * torch.exp(-r ** (2 * p[3]) / (2 * self.sigma ** 2)))\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe training data is generated with the above Pytorch Geometric model\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nsigma = config.simulation.sigma\nmodel = AttractionRepulsionModel(\n    p=p,\n    sigma=sigma,\n    bc_dpos=bc_dpos,\n)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\nThe GNN model (see src/ParticleGraph/models/Interaction_Particle.py) is trained and tested.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nThe model that has been trained in the previous step is used to generate the rollouts. The rollout visualization can be found in paper_experiments/log/try_arbitrary_3_3/tmp_recons.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate the figures that are shown in Figure 3.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nInitial configuration of the test training dataset. There are 4800 particles. The orange, blue, and green particles represent the three different particle types.\n\n\n\n\n\n\n\n\n\nFinal configuration at frame 250\n\n\n\n\n\n\n\n\n\nLearned latent vectors (x4800)\n\n\n\n\n\n\n\n\n\nLearned interaction functions (x3)\n\n\n\n\n\n\n\n\n\nGNN rollout inference at frame 250"
  },
  {
    "objectID": "paper_experiments/create_fig_3_3.html",
    "href": "paper_experiments/create_fig_3_3.html",
    "title": "Training GNN on attraction-repulsion (continuous function domain)",
    "section": "",
    "text": "This script creates the third column of paper’s Figure 3. A GNN learns the motion rules of an attraction-repulsion system. The simulation used to train the GNN consists of 4800 particles of many different types. The particles interact with each other according to many different attraction-repulsion laws.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'arbitrary_3_continuous'\nfigure_id = '3_3'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the attraction-repulsion system with PyTorch Geometric.\n\nclass AttractionRepulsionModel(pyg.nn.MessagePassing):\n    \"\"\"\n    Compute the speed of particles as a function of their relative position according to an attraction-repulsion law.\n    The latter is defined by four parameters p = (p1, p2, p3, p4) and a parameter sigma.\n\n    See https://github.com/gpeyre/numerical-tours/blob/master/python/ml_10_particle_system.ipynb\n    \"\"\"\n\n    def __init__(self, p, sigma, bc_dpos, dimension=2):\n        super(AttractionRepulsionModel, self).__init__(aggr='mean')\n\n        self.p = p\n        self.sigma = sigma\n        self.bc_dpos = bc_dpos\n        self.dimension = dimension\n\n    def forward(self, data: Data):\n        x, edge_index = data.x, data.edge_index\n\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 1 + 2 * self.dimension])\n        parameters = self.p[particle_type,:]\n        d_pos = self.propagate(edge_index, pos=x[:, 1:self.dimension + 1], parameters=parameters)\n        return d_pos\n\n    def message(self, pos_i, pos_j, parameters_i):\n\n        relative_position = self.bc_dpos(pos_j - pos_i)\n        distance_squared = torch.sum(relative_position ** 2, dim=1)  # squared distance\n        f = (parameters_i[:, 0] * torch.exp(-distance_squared ** parameters_i[:, 1] / (2 * self.sigma ** 2))\n             - parameters_i[:, 2] * torch.exp(-distance_squared ** parameters_i[:, 3] / (2 * self.sigma ** 2)))\n        velocity = f[:, None] * relative_position\n\n        return velocity\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe training data is generated with the above Pytorch Geometric model\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nsigma = config.simulation.sigma\nmodel = AttractionRepulsionModel(\n    p=p,\n    sigma=sigma,\n    bc_dpos=bc_dpos,\n    dimension=config.simulation.dimension\n)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\nThe GNN model (see src/ParticleGraph/models/Interaction_Particle.py) is trained and tested.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nThe model that has been trained in the previous step is used to generate the rollouts. The rollout visualization can be found in paper_experiments/log/try_arbitrary_3_continuous/tmp_recons.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate the figures that are shown in Figure 3.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nInitial configuration of the test training dataset. There are 4800 particles.\n\n\n\n\n\n\n\n\n\nFinal configuration at frame 1000.\n\n\n\n\n\n\n\n\n\nLearned latent vectors (x4800)\n\n\n\n\n\n\n\n\n\nLearned interaction functions (x4800)\n\n\n\n\n\n\n\n\n\nGNN rollout inference at frame 1000"
  },
  {
    "objectID": "paper_experiments/create_fig_2_7.html",
    "href": "paper_experiments/create_fig_2_7.html",
    "title": "Signaling system with 998 nodes",
    "section": "",
    "text": "This script creates the seventh column of paper’s Figure 2. Simulation of a signaling network, 986 nodes, 17,865 edges, 2 types of nodes. Note 100 of datasets are generated to test training with multiple trials.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'signal_N_100_2'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the signaling network with PyTorch Geometric.\n\nclass SignalingNetwork(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n\n    Returns\n    -------\n    pred : float\n\n    \"\"\"\n\n    def __init__(self, aggr_type=[], p=[], bc_dpos=[]):\n        super(SignalingNetwork, self).__init__(aggr=aggr_type)\n\n        self.p = p\n        self.bc_dpos = bc_dpos\n\n    def forward(self, data=[], return_all=False):\n        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = x[:, 5].long()\n        parameters = self.p[particle_type]\n        b = parameters[:, 0:1]\n        c = parameters[:, 1:2]\n\n        u = x[:, 6:7]\n\n        msg = self.propagate(edge_index, u=u, edge_attr=edge_attr)\n\n        du = -b * u + c * torch.tanh(u) + msg\n\n        if return_all:\n            return du, -b * u + c * torch.tanh(u), msg\n        else:\n            return du\n\n    def message(self, u_j, edge_attr):\n\n        self.activation = torch.tanh(u_j)\n        self.u_j = u_j\n\n        return edge_attr[:, None] * torch.tanh(u_j)\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe data is generated with the above Pytorch Geometric model. If the simulation is too large, you can decrease n_particles (multiple of 2) and n_nodes in “signal_N_100_2.yaml”\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nmodel = SignalingNetwork(aggr_type=config.graph_model.aggr_type, p=torch.squeeze(p), bc_dpos=bc_dpos)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_synaptic(config, model, **generate_kwargs)\n\nFinally, we generate the figures that are shown in Figure 2. The frames of the first six datasets are saved in ‘decomp-gnn/paper_experiments/graphs_data/graphs_signal_N_100_2/Fig/’.\n\n\n\n\n\nInitial configuration of the simulation. There are 998 nodes. The colors indicate the node scalar values.\n\n\n\n\n\n\n\n\n\nFrame 300 out of 1000\n\n\n\n\n\n\n\n\n\nFrame 600 out of 1000\n\n\n\n\n\n\n\n\n\nFrame 900 out of 1000"
  },
  {
    "objectID": "paper_experiments/create_fig_coulomb.html",
    "href": "paper_experiments/create_fig_coulomb.html",
    "title": "Training GNN on Coulomb-like system",
    "section": "",
    "text": "This script generates figures shown in Supplementary Figure 8. A GNN learns the motion rules governing a gravity-like system The simulation used to train the GNN consists of 960 particles of 16 different masses. The particles interact with each other according to gravity law.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'Coulomb_3_256'\nfigure_id = 'supp8'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the gravity-like system with PyTorch Geometric.\n\nclass CoulombModel(pyg.nn.MessagePassing):\n        \"\"\"Interaction Network as proposed in this paper:\n        https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n        \"\"\"\n        Compute the acceleration of charged particles as a function of their relative position according to the Coulomb law.\n\n        Inputs\n        ----------\n        data : a torch_geometric.data object\n\n        Returns\n        -------\n        pred : float\n            the acceleration of the particles (dimension 2)\n        \"\"\"\n\n        def __init__(self, aggr_type=[], p=[], clamp=[], pred_limit=[], bc_dpos=[]):\n            super(CoulombModel, self).__init__(aggr='add')  # \"mean\" aggregation.\n\n            self.p = p\n            self.clamp = clamp\n            self.pred_limit = pred_limit\n            self.bc_dpos = bc_dpos\n\n        def forward(self, data):\n            x, edge_index = data.x, data.edge_index\n            edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n            particle_type = to_numpy(x[:, 5])\n            charge = self.p[particle_type]\n            dd_pos = self.propagate(edge_index, pos=x[:, 1:3], charge=charge[:, None])\n            return dd_pos\n\n        def message(self, pos_i, pos_j, charge_i, charge_j):\n            distance_ij = torch.sqrt(torch.sum(self.bc_dpos(pos_j - pos_i) ** 2, axis=1))\n            direction_ij = self.bc_dpos(pos_j - pos_i) / distance_ij[:, None]\n            dd_pos = - charge_i * charge_j * direction_ij / (distance_ij[:, None] ** 2)\n            return dd_pos\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe data is generated with the above Pytorch Geometric model. Note two datasets are generated, one for training and one for validation. If the simulation is too large, you can decrease n_particles (multiple of 3) in “Coulomb_3_256.yaml”.#\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nmodel = CoulombModel(aggr_type=config.graph_model.aggr_type, p=torch.squeeze(p),\n                          clamp=config.training.clamp, pred_limit=config.training.pred_limit, bc_dpos=bc_dpos)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=20, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\n\n\n\n\n\nInitial configuration of the simulation. There are 960 particles. The colors indicate different charges.\n\n\n\n\n\n\n\n\n\nFrame 1800 out of 2000\n\n\n\n\nThe GNN model (see src/ParticleGraph/models/Interaction_Particle.py) is trained and tested.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nDuring training the embedding is saved in “paper_experiments/log/try_gravity_16/tmp_training/embedding” The plot of the pairwise interactions is saved in “paper_experiments/log/try_gravity_16/tmp_training/function”\nThe model that has been trained in the previous step is used to generate the rollouts.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate the figures that are shown in Supplementary Figure 7. The results of the GNN post-analysis are saved into ‘decomp-gnn/paper_experiments/log/try_Coulomb_3_256/results’.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nLearned latent vectors (x960)\n\n\n\n\n\n\n\n\n\nLearned interaction functions\n\n\n\n\n\n\n\n\n\nGNN rollout inference at frame 1980\n\n\n\n\nAll frames can be found in “decomp-gnn/paper_experiments/log/try_Coulomb_3_256/tmp_recons/”"
  },
  {
    "objectID": "paper_experiments/create_fig_2_6.html",
    "href": "paper_experiments/create_fig_2_6.html",
    "title": "Reaction-diffusion propagation with different diffusion coefficients",
    "section": "",
    "text": "This script creates the sixth column of paper’s Figure 2. Simulation of reaction-diffusion over a mesh of 1E4 nodes with variable propagation-coefficients.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'RD_RPS'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the reaction_diffusion propagation with PyTorch Geometric.\n\nclass RDModel(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the reaction diffusion according to the rock paper scissor model.\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n    Note the Laplacian coeeficients are in data.edge_attr\n\n    Returns\n    -------\n    increment : float\n        the first derivative of three scalar fields u, v and w\n\n    \"\"\"\n\n    def __init__(self, aggr_type=[], bc_dpos=[], coeff = []):\n        super(RDModel, self).__init__(aggr='add')  # \"mean\" aggregation.\n\n        self.bc_dpos = bc_dpos\n        self.coeff = coeff\n        self.a = 0.6\n\n    def forward(self, data):\n        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n\n        c = self.coeff\n\n        uvw = data.x[:, 6:9]\n        laplace_uvw = c * self.propagate(data.edge_index, uvw=uvw, discrete_laplacian=data.edge_attr)\n        p = torch.sum(uvw, axis=1)\n\n        d_uvw = laplace_uvw + uvw * (1 - p[:, None] - self.a * uvw[:, [1, 2, 0]])\n        # This is equivalent to the nonlinear reaction diffusion equation:\n        #   du = c * laplace_u + u * (1 - p - a * v)\n        #   dv = c * laplace_v + v * (1 - p - a * w)\n        #   dw = c * laplace_w + w * (1 - p - a * u)\n\n        return d_uvw\n\n    def message(self, uvw_j, discrete_laplacian):\n        return discrete_laplacian[:, None] * uvw_j\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe data is generated with the above Pytorch Geometric model. Note two datasets are generated, one for training and one for validation. If the simulation is too large, you can decrease n_particles (multiple of 5) and n_nodes in “RD_RPS.yaml”\n\nmodel = RDModel(aggr_type=config.graph_model.aggr_type, bc_dpos=bc_dpos)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', erase=False, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_mesh(config, model , **generate_kwargs)\n\nFinally, we generate the figures that are shown in Figure 2. All frames are saved in ‘decomp-gnn/paper_experiments/graphs_data/graphs_RD_RPS/Fig/’.\n\n\n\n\n\nInitial configuration of the simulation. There are 1E4 nodes. The colors indicate the node vector values.\n\n\n\n\n\n\n\n\n\nFrame 1250 out of 4000\n\n\n\n\n\n\n\n\n\nFrame 2500 out of 4000\n\n\n\n\n\n\n\n\n\nFrame 3750 out of 4000"
  },
  {
    "objectID": "paper_experiments/create_fig_boids.html",
    "href": "paper_experiments/create_fig_boids.html",
    "title": "Training GNN on boids (16 types)",
    "section": "",
    "text": "This script generates figures shown in Supplementary Figures 4, 11 and 12. A GNN learns the motion rules of boids (https://en.wikipedia.org/wiki/Boids). The simulation used to train the GNN consists of 1792 particles of 16 different types. The boids interact with each other according to 16 different laws.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'boids_16_256'\nfigure_id = 'supp4'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the boids system with PyTorch Geometric.\n\nclass BoidsModel(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the acceleration of Boids as a function of their relative positions and relative positions.\n    The interaction function is defined by three parameters p = (p1, p2, p3)\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n\n    Returns\n    -------\n    pred : float\n        the acceleration of the Boids (dimension 2)\n    \"\"\"\n\n    def __init__(self, aggr_type=[], p=[], bc_dpos=[], dimension=2):\n        super(BoidsModel, self).__init__(aggr=aggr_type)  # \"mean\" aggregation.\n\n        self.p = p\n        self.bc_dpos = bc_dpos\n        self.dimension = dimension\n\n        self.a1 = 0.5E-5\n        self.a2 = 5E-4\n        self.a3 = 1E-8\n        self.a4 = 0.5E-5\n        self.a5 = 1E-8\n\n    def forward(self, data=[], has_field=False):\n        x, edge_index = data.x, data.edge_index\n\n        if has_field:\n            field = x[:,6:7]\n        else:\n            field = torch.ones_like(x[:,0:1])\n\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 1 + 2*self.dimension])\n        parameters = self.p[particle_type, :]\n        d_pos = x[:, self.dimension+1:1 + 2*self.dimension].clone().detach()\n        dd_pos = self.propagate(edge_index, pos=x[:, 1:self.dimension+1], parameters=parameters, d_pos=d_pos, field=field)\n\n        return dd_pos\n\n    def message(self, pos_i, pos_j, parameters_i, d_pos_i, d_pos_j, field_j):\n        distance_squared = torch.sum(self.bc_dpos(pos_j - pos_i) ** 2, axis=1)  # distance squared\n\n        cohesion = parameters_i[:,0,None] * self.a1 * self.bc_dpos(pos_j - pos_i)\n        alignment = parameters_i[:,1,None] * self.a2 * self.bc_dpos(d_pos_j - d_pos_i)\n        separation = - parameters_i[:,2,None] * self.a3 * self.bc_dpos(pos_j - pos_i) / distance_squared[:, None]\n\n        return (separation + alignment + cohesion) * field_j\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe training data is generated with the above Pytorch Geometric model\nVizualizations of the boids motion can be found in “decomp-gnn/paper_experiments/graphs_data/graphs_boids_16_256/Fig/”\nIf the simulation is too large, you can decrease n_particles (multiple of 16) in “boids_16_256.yaml”\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nmodel = BoidsModel(aggr_type=config.graph_model.aggr_type, p=torch.squeeze(p), bc_dpos=bc_dpos, dimension=config.simulation.dimension)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=100)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=50, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\n\n\n\n\n\nInitial configuration of the simulation. There are 1792 boids. The colors indicate different types.\n\n\n\n\n\n\n\n\n\nFrame 7500 out of 8000\n\n\n\n\nThe GNN model (see src/ParticleGraph/models/Interaction_Particle.py) is trained and tested.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nDuring training the plot of the embedding are saved in “paper_experiments/log/try_boids_16_256/tmp_training/embedding” The plot of the pairwise interactions are saved in “paper_experiments/log/try_boids_16_256/tmp_training/function”\nThe model that has been trained in the previous step is used to generate the rollouts.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate figures from the post-analysis of the GNN. The results of the GNN post-analysis are saved into ‘decomp-gnn/paper_experiments/log/try_boids_16_256/results’.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nLearned latent vectors (x4800)\n\n\n\n\n\n\n\n\n\nLearned interaction functions (x16)\n\n\n\n\n\n\n\n\n\nLearned cohesion parameters\n\n\n\n\n\n\n\n\n\nLearned alignment parameters\n\n\n\n\n\n\n\n\n\nLearned separation parameters\n\n\n\n\n\n\n\n\n\nGNN rollout inference at frame 7950\n\n\n\n\nAll frames can be found in “decomp-gnn/paper_experiments/log/try_boids_16_256/tmp_recons/”"
  },
  {
    "objectID": "paper_experiments/create_fig_2_3.html",
    "href": "paper_experiments/create_fig_2_3.html",
    "title": "Coulomb-like system with different particle charges",
    "section": "",
    "text": "This script creates the third column of paper’s Figure 2. Simulation of a Coulomb-like system: 960 particles, 3 different charges.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'Coulomb_3_256'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the Coulomb-like system with PyTorch Geometric. There are three possible charges: -1, 1, and 2.\n\nclass CoulombModel(pyg.nn.MessagePassing):\n        \"\"\"Interaction Network as proposed in this paper:\n        https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n        \"\"\"\n        Compute the acceleration of charged particles as a function of their relative position according to the Coulomb law.\n\n        Inputs\n        ----------\n        data : a torch_geometric.data object\n\n        Returns\n        -------\n        pred : float\n            the acceleration of the particles (dimension 2)\n        \"\"\"\n\n        def __init__(self, aggr_type=[], p=[], clamp=[], pred_limit=[], bc_dpos=[]):\n            super(CoulombModel, self).__init__(aggr='add')  # \"mean\" aggregation.\n\n            self.p = p\n            self.clamp = clamp\n            self.pred_limit = pred_limit\n            self.bc_dpos = bc_dpos\n\n        def forward(self, data):\n            x, edge_index = data.x, data.edge_index\n            edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n            particle_type = to_numpy(x[:, 5])\n            charge = self.p[particle_type]\n            dd_pos = self.propagate(edge_index, pos=x[:, 1:3], charge=charge[:, None])\n            return dd_pos\n\n        def message(self, pos_i, pos_j, charge_i, charge_j):\n            distance_ij = torch.sqrt(torch.sum(self.bc_dpos(pos_j - pos_i) ** 2, axis=1))\n            direction_ij = self.bc_dpos(pos_j - pos_i) / distance_ij[:, None]\n            dd_pos = - charge_i * charge_j * direction_ij / (distance_ij[:, None] ** 2)\n            return dd_pos\n\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe data is generated with the above Pytorch Geometric model. Note two datasets are generated, one for training and one for validation. If the simulation is too large, you can decrease n_particles (multiple of 3) in “Coulomb_3_256.yaml”.#\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nmodel = CoulombModel(aggr_type=config.graph_model.aggr_type, p=torch.squeeze(p),\n                          clamp=config.training.clamp, pred_limit=config.training.pred_limit, bc_dpos=bc_dpos)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\nFinally, we generate the figures that are shown in Figure 2. All frames are saved in ‘decomp-gnn/paper_experiments/graphs_data/graphs_Coulomb_3_256/Fig/’.\n\n\n\n\n\nInitial configuration of the simulation. There are 960 particles. The colors indicate different charges.\n\n\n\n\n\n\n\n\n\nFrame 600 out of 2000\n\n\n\n\n\n\n\n\n\nFrame 1200 out of 2000\n\n\n\n\n\n\n\n\n\nFrame 1800 out of 2000"
  },
  {
    "objectID": "paper_experiments/create_fig_boids_supp13.html",
    "href": "paper_experiments/create_fig_boids_supp13.html",
    "title": "Generalization test of GNN trained on boids",
    "section": "",
    "text": "This script generates figures shown in Supplementary Figures 13. This is a generalization test of the GNN trained with the boids simulation . As a generalization test, the number of particle was multiplied by a factor of 4 (from 1,792 to 7,168) and the initial positions were split into 16 stripes to separate particle types.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'boids_16_256_bis'\nfigure_id = 'supp13'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the boids system with PyTorch Geometric.\n\nclass BoidsModel(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the acceleration of Boids as a function of their relative positions and relative positions.\n    The interaction function is defined by three parameters p = (p1, p2, p3)\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n\n    Returns\n    -------\n    pred : float\n        the acceleration of the Boids (dimension 2)\n    \"\"\"\n\n    def __init__(self, aggr_type=[], p=[], bc_dpos=[], dimension=2):\n        super(BoidsModel, self).__init__(aggr=aggr_type)  # \"mean\" aggregation.\n\n        self.p = p\n        self.bc_dpos = bc_dpos\n        self.dimension = dimension\n\n        self.a1 = 0.5E-5\n        self.a2 = 5E-4\n        self.a3 = 1E-8\n        self.a4 = 0.5E-5\n        self.a5 = 1E-8\n\n    def forward(self, data=[], has_field=False):\n        x, edge_index = data.x, data.edge_index\n\n        if has_field:\n            field = x[:,6:7]\n        else:\n            field = torch.ones_like(x[:,0:1])\n\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 1 + 2*self.dimension])\n        parameters = self.p[particle_type, :]\n        d_pos = x[:, self.dimension+1:1 + 2*self.dimension].clone().detach()\n        dd_pos = self.propagate(edge_index, pos=x[:, 1:self.dimension+1], parameters=parameters, d_pos=d_pos, field=field)\n\n        return dd_pos\n\n    def message(self, pos_i, pos_j, parameters_i, d_pos_i, d_pos_j, field_j):\n        distance_squared = torch.sum(self.bc_dpos(pos_j - pos_i) ** 2, axis=1)  # distance squared\n\n        cohesion = parameters_i[:,0,None] * self.a1 * self.bc_dpos(pos_j - pos_i)\n        alignment = parameters_i[:,1,None] * self.a2 * self.bc_dpos(d_pos_j - d_pos_i)\n        separation = - parameters_i[:,2,None] * self.a3 * self.bc_dpos(pos_j - pos_i) / distance_squared[:, None]\n\n        return (separation + alignment + cohesion) * field_j\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe gneralization test data is generated with the above Pytorch Geometric model\nVizualizations of the boids motion can be found in “decomp-gnn/paper_experiments/graphs_data/graphs_boids_16_256_bis/Fig/”\nIf the simulation is too large, you can set ratio to 1 in kwargs and/or decrease n_particles (multiple of 16) in “boids_16_256_bis.yaml”\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nmodel = BoidsModel(aggr_type=config.graph_model.aggr_type, p=torch.squeeze(p), bc_dpos=bc_dpos, dimension=config.simulation.dimension)\n\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, scenario='stripes', ratio=4, save=True, step=100)\n\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0,  ratio=4, sample_embedding=True, step=100, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\n\n\n\n\n\nInitial configuration of the simulation. There are 1792 boids. The colors indicate different types.\n\n\n\n\n\n\n\n\n\nFrame 2000 out of 8000\n\n\n\n\n\n\n\n\n\nFrame 2000 out of 4000\n\n\n\n\n\n\n\n\n\nFrame 7500 out of 8000\n\n\n\n\nThe model that has been trained is used to generate the rollouts from the new dataset.\n\ndata_test(config, config_file, **test_kwargs)\n\nThe results of the GNN is plotted’.\n\n\n\n\n\nInitial configuration of the simulation. There are 1792 boids. The colors indicate different types.\n\n\n\n\n\n\n\n\n\nFrame 2000 out of 8000\n\n\n\n\n\n\n\n\n\nFrame 2000 out of 4000\n\n\n\n\n\n\n\n\n\nFrame 7500 out of 8000\n\n\n\n\nAll frames can be found in “decomp-gnn/paper_experiments/log/try_boids_16_256_bis/tmp_recons/”"
  },
  {
    "objectID": "paper_experiments/create_fig_signal.html",
    "href": "paper_experiments/create_fig_signal.html",
    "title": "Training GNN on signaling",
    "section": "",
    "text": "This script generates figures shown in Supplementary Figures 18. A GNN is trained on a signaling network (998 nodes, 17,865 edges). Note 100 of datasets are generated for training.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'signal_N_100_2'\nfigure_id = 'supp18'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the signaling network with PyTorch Geometric.\n\nclass SignalingNetwork(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n\n    Returns\n    -------\n    pred : float\n\n    \"\"\"\n\n    def __init__(self, aggr_type=[], p=[], bc_dpos=[]):\n        super(SignalingNetwork, self).__init__(aggr=aggr_type)\n\n        self.p = p\n        self.bc_dpos = bc_dpos\n\n    def forward(self, data=[], return_all=False):\n        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = x[:, 5].long()\n        parameters = self.p[particle_type]\n        b = parameters[:, 0:1]\n        c = parameters[:, 1:2]\n\n        u = x[:, 6:7]\n\n        msg = self.propagate(edge_index, u=u, edge_attr=edge_attr)\n\n        du = -b * u + c * torch.tanh(u) + msg\n\n        if return_all:\n            return du, -b * u + c * torch.tanh(u), msg\n        else:\n            return du\n\n    def message(self, u_j, edge_attr):\n\n        self.activation = torch.tanh(u_j)\n        self.u_j = u_j\n\n        return edge_attr[:, None] * torch.tanh(u_j)\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe data is generated with the above Pytorch Geometric model. If the simulation is too large, you can decrease n_particles (multiple of 2) and n_nodes in “signal_N_100_2.yaml”\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nmodel = SignalingNetwork(aggr_type=config.graph_model.aggr_type, p=torch.squeeze(p), bc_dpos=bc_dpos)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='7', run=0, step=10, save_velocity=True)\n\ndata_generate_synaptic(config, model, **generate_kwargs)\n\nFinally, we generate the figures that are shown in Figure 2. The frames of the first six datasets are saved in ‘decomp-gnn/paper_experiments/graphs_data/graphs_signal_N_100_2/Fig/’.\n\n\n\n\n\nInitial configuration of the simulation. There are 998 nodes. The colors indicate the node scalar values.\n\n\n\n\n\n\n\n\n\nFrame 300 out of 1000\n\n\n\n\n\n\n\n\n\nFrame 600 out of 1000\n\n\n\n\n\n\n\n\n\nFrame 900 out of 1000\n\n\n\n\nThe GNN model (see src/ParticleGraph/models/Signal_Propagation.py) is trained and tested.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nDuring training the plot of the embedding are saved in “paper_experiments/log/try_signal_N_100_2/tmp_training/embedding” The plot of the pairwise interactions are saved in “paper_experiments/log/try_signal_N_100_2/tmp_training/function”\nThe model that has been trained in the previous step is used to generate the rollouts.\n\ndata_test(config, config_file, **test_kwargs)\n\n\n\n\n\n\nFrame 0 out of 1000\n\n\n\n\n\n\n\n\n\nFrame 250 out of 1000\n\n\n\n\n\n\n\n\n\nFrame 500 out of 1000\n\n\n\n\n\n\n\n\n\nFrame 750 out of 1000\n\n\n\n\nFinally, we generate figures from the post-analysis of the GNN. The results of the GNN post-analysis are saved into ‘decomp-gnn/paper_experiments/log/try_signal_N_100_2/results’.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nComparison between the learned and the true connectivity matrix values\n\n\n\n\n\n\n\n\n\nComparison between the learned and the true transfert functions\n\n\n\n\n\n\n\n\n\nComparison between the learned and the true update functions (neuron type 1)\n\n\n\n\n\n\n\n\n\nComparison between the learned and the true update functions (neuron type 2)"
  },
  {
    "objectID": "paper_experiments/create_fig_rps.html",
    "href": "paper_experiments/create_fig_rps.html",
    "title": "Training GNN on reaction-diffusion (rock-paper-scissors)",
    "section": "",
    "text": "This script generates Supplementary Figure 17. It showcases a Graph Neural Network (GNN) learning the dynamics of a reaction-diffusion system. The training simulation involves 1E4 mesh nodes observed over 4E3 frames. Node interactions follow rock-paper-scissors rules with different diffusion coefficients.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'RD_RPS'\nfigure_id = 'supp17'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the ‘rock-paper-scissor’ model with PyTorch Geometric.\n\nclass RDModel(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the reaction diffusion according to the rock paper scissor model.\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n    Note the Laplacian coeeficients are in data.edge_attr\n\n    Returns\n    -------\n    increment : float\n        the first derivative of three scalar fields u, v and w\n\n    \"\"\"\n\n    def __init__(self, aggr_type=[], bc_dpos=[], coeff = []):\n        super(RDModel, self).__init__(aggr='add')  # \"mean\" aggregation.\n\n        self.bc_dpos = bc_dpos\n        self.coeff = coeff\n        self.a = 0.6\n\n    def forward(self, data):\n        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n\n        c = self.coeff\n\n        uvw = data.x[:, 6:9]\n        laplace_uvw = c * self.propagate(data.edge_index, uvw=uvw, discrete_laplacian=data.edge_attr)\n        p = torch.sum(uvw, axis=1)\n\n        d_uvw = laplace_uvw + uvw * (1 - p[:, None] - self.a * uvw[:, [1, 2, 0]])\n        # This is equivalent to the nonlinear reaction diffusion equation:\n        #   du = D * laplace_u + u * (1 - p - a * v)\n        #   dv = D * laplace_v + v * (1 - p - a * w)\n        #   dw = D * laplace_w + w * (1 - p - a * u)\n\n        return d_uvw\n\n    def message(self, uvw_j, discrete_laplacian):\n        return discrete_laplacian[:, None] * uvw_j\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe coefficients of diffusion are loaded from a tif file specified in the config yaml file and the data is generated.\nVizualizations of the reaction diffusion can be found in “decomp-gnn/paper_experiments/graphs_data/RD_RPS/”\nIf the simulation is too large, you can decrease n_particles and n_nodes in “RD_RPS.yaml”.\n\nmodel = RDModel(\n    aggr_type='add',\n    bc_dpos=bc_dpos)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', erase=False, save=True, step=50)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=20)\n\ndata_generate_mesh(config, model , **generate_kwargs)\n\n\n\n\n\n\nInitial configuration of the simulation. There are 1E4 nodes. The colors indicate the node vector values.\n\n\n\n\n\n\n\n\n\nFrame 3750 out of 4000\n\n\n\n\nThe GNN model (see src/ParticleGraph/models/Mesh_RPS.py) is optimized using the ‘rock-paper-scissor’ data.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nThe model that has been trained in the previous step is used to generate the rollouts. The rollout visualization can be found in paper_experiments/log/try_RD_RPS/tmp_recons.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate the figures that are shown in Supplementary Figure 17. The results of the GNN post-analysis are saved into ‘decomp-gnn/paper_experiments/log/try_RD_RPS/results’.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nLearned latent vectors (x1E4)\n\n\n\n\n\n\n\n\n\nLearned map of of node type\n\n\n\n\n\n\n\n\n\nComparison between true and learned coefficients of diffusion\n\n\n\n\n\n\n\n\n\nComparison between true (blue) and learned (orange) polynomial coefficients of the first governing equation\n\n\n\n\n\n\n\n\n\nComparison between true (blue) and learned (orange) polynomial coefficients of the second governing equation\n\n\n\n\n\n\n\n\n\nComparison between true (blue) and learned (orange) polynomial coefficients of the third gooverning equation\n\n\n\n\n\n\n\n\n\nGNN rollout inference at frame 3980\n\n\n\n\nAll frames can be found in “decomp-gnn/paper_experiments/log/try_RD_RPS/tmp_recons/”"
  },
  {
    "objectID": "paper_experiments/create_fig_3_5.html",
    "href": "paper_experiments/create_fig_3_5.html",
    "title": "Training GNN on attraction-repulsion (32 particle types)",
    "section": "",
    "text": "This script creates the fifth column of paper’s Figure 3. A GNN learns the motion rules of an attraction-repulsion system. The simulation used to train the GNN consists of 4800 particles of three different types. The particles interact with each other according to 32 different attraction-repulsion laws.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'arbitrary_32'\nfigure_id = '3_5'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the attraction-repulsion system with PyTorch Geometric.\n\nclass AttractionRepulsionModel(pyg.nn.MessagePassing):\n    \"\"\"\n    Compute the speed of particles as a function of their relative position according to an attraction-repulsion law.\n    The latter is defined by four parameters p = (p1, p2, p3, p4) and a parameter sigma.\n\n    See https://github.com/gpeyre/numerical-tours/blob/master/python/ml_10_particle_system.ipynb\n    \"\"\"\n\n    def __init__(self, p, sigma, bc_dpos, dimension=2):\n        super(AttractionRepulsionModel, self).__init__(aggr='mean')\n\n        self.p = p\n        self.sigma = sigma\n        self.bc_dpos = bc_dpos\n        self.dimension = dimension\n\n    def forward(self, data: Data):\n        x, edge_index = data.x, data.edge_index\n\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 1 + 2 * self.dimension])\n        parameters = self.p[particle_type,:]\n        d_pos = self.propagate(edge_index, pos=x[:, 1:self.dimension + 1], parameters=parameters)\n        return d_pos\n\n\n    def message(self, pos_i, pos_j, parameters_i):\n\n        relative_position = self.bc_dpos(pos_j - pos_i)\n        distance_squared = torch.sum(relative_position ** 2, dim=1)  # squared distance\n        f = (parameters_i[:, 0] * torch.exp(-distance_squared ** parameters_i[:, 1] / (2 * self.sigma ** 2))\n             - parameters_i[:, 2] * torch.exp(-distance_squared ** parameters_i[:, 3] / (2 * self.sigma ** 2)))\n        velocity = f[:, None] * relative_position\n\n        return velocity\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe training data is generated with the above Pytorch Geometric model\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nsigma = config.simulation.sigma\nmodel = AttractionRepulsionModel(\n    p=p,\n    sigma=sigma,\n    bc_dpos=bc_dpos,\n    dimension=config.simulation.dimension\n)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\nThe GNN model (see src/ParticleGraph/models/Interaction_Particle.py) is trained and tested.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nThe model that has been trained in the previous step is used to generate the rollouts. The rollout visualization can be found in paper_experiments/log/try_arbitrary_32/tmp_recons.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate the figures that are shown in Figure 3.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nInitial configuration of the test training dataset. There are 4800 particles. Colors indicate the particle types.\n\n\n\n\n\n\n\n\n\nFinal configuration at frame 1000\n\n\n\n\n\n\n\n\n\nLearned latent vectors (x4800)\n\n\n\n\n\n\n\n\n\nLearned interaction functions (x32)\n\n\n\n\n\n\n\n\n\nGNN rollout inference"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Decomposing heterogeneous dynamical systems with graph neural networks",
    "section": "",
    "text": "This site shows the code to generate some figures from the “Decomposing heterogeneous dynamical systems with graph neural networks” paper.\nWe showed with a diverse set of simulations that message passing GNNs that jointly learn interaction, update functions and latent node properties are a flexible tool to predict, decompose, and eventually understand complex dynamical systems. With the currently available PyTorch Geometric software libraries, it is straightforward to implement a differentiable architecture and loss that encode useful assumptions about the structure of the complex system such as local connectivity rules or the location of learnable and known functions and their inputs. In particular, a well designed GNN can learn a low-dimensional embedding of complex latent properties required to parameterize heterogeneous particle-particle interactions. The learned embeddings can be used to reveal the structure of latent properties underlying the complex dynamics and to infer the corresponding parameters. It is possible to dissect the dynamical system and conduct virtual experiments with arbitrary compositions of particles and interactions. This ability will be particularly important for understanding the behavior of heterogeneous dynamical systems in biology that can only be observed in their natural, mixed configurations. Examples include bacterial community organization, embryonic development, neural networks, and the social interactions of animal communities, which cannot be studied in isolation.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAttraction-repulsion system with 3 particle types\n\n\n\n\n\n\nParticles\n\n\nSimulation\n\n\n\n\n\n\n\n\n\ncreate_fig_2_1.py\n\n\n\n\n\n\n\n\n\n\n\n\nBoids system with 16 different particle types\n\n\n\n\n\n\nParticles\n\n\nSimulation\n\n\n\n\n\n\n\n\n\ncreate_fig_2_4.py\n\n\n\n\n\n\n\n\n\n\n\n\nCoulomb-like system with different particle charges\n\n\n\n\n\n\nParticles\n\n\nSimulation\n\n\n\n\n\n\n\n\n\ncreate_fig_2_3.py\n\n\n\n\n\n\n\n\n\n\n\n\nGeneralization test of GNN trained on boids\n\n\n\n\n\n\nParticles\n\n\nGeneralization Test\n\n\n\n\n\n\n\n\n\ncreate_fig_boids_supp13.py\n\n\n\n\n\n\n\n\n\n\n\n\nGravity-like system with different particle masses\n\n\n\n\n\n\nParticles\n\n\nSimulation\n\n\n\n\n\n\n\n\n\ncreate_fig_2_2.py\n\n\n\n\n\n\n\n\n\n\n\n\nReaction-diffusion propagation with different diffusion coefficients\n\n\n\n\n\n\nMesh\n\n\nSimulation\n\n\n\n\n\n\n\n\n\ncreate_fig_2_6.py\n\n\n\n\n\n\n\n\n\n\n\n\nSignaling system with 998 nodes\n\n\n\n\n\n\nSignaling\n\n\nSimulation\n\n\n\n\n\n\n\n\n\ncreate_fig_2_7.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on Coulomb-like system\n\n\n\n\n\n\nParticles\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_coulomb.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on attraction-repulsion (16 particle types)\n\n\n\n\n\n\nParticles\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_3_4.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on attraction-repulsion (3 particle types)\n\n\n\n\n\n\nParticles\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_3_1.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on attraction-repulsion (32 particle types)\n\n\n\n\n\n\nParticles\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_3_5.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on attraction-repulsion (64 particle types)\n\n\n\n\n\n\nParticles\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_3_6.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on attraction-repulsion (asymmetric, 3 particle types)\n\n\n\n\n\n\nParticles\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_3_2.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on attraction-repulsion (continuous function domain)\n\n\n\n\n\n\nParticles\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_3_3.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on attraction-repulsion (hidden field)\n\n\n\n\n\n\nParticles\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_4.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on boids (16 types)\n\n\n\n\n\n\nParticles\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_boids.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on gravity-like system\n\n\n\n\n\n\nParticles\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_gravity.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on reaction-diffusion (rock-paper-scissors)\n\n\n\n\n\n\nMesh\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_rps.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on signaling\n\n\n\n\n\n\nSignaling\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_signal.py\n\n\n\n\n\n\n\n\n\n\n\n\nTraining GNN on wave propagation\n\n\n\n\n\n\nMesh\n\n\nGNN Training\n\n\n\n\n\n\n\n\n\ncreate_fig_wave.py\n\n\n\n\n\n\n\n\n\n\n\n\nWave propagation with different diffusion coefficients\n\n\n\n\n\n\nMesh\n\n\nSimulation\n\n\n\n\n\n\n\n\n\ncreate_fig_2_5.py\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "paper_experiments/create_fig_2_2.html",
    "href": "paper_experiments/create_fig_2_2.html",
    "title": "Gravity-like system with different particle masses",
    "section": "",
    "text": "This script creates the second column of paper’s Figure 2. Simulation of a gravity-like system, 960 particles, 16 different masses.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'gravity_16'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the gravity-like system with PyTorch Geometric.\n\nclass GravityModel(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the acceleration of particles as a function of their relative position according to the gravity law.\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n\n    Returns\n    -------\n    pred : float\n        the acceleration of the particles (dimension 2)\n    \"\"\"\n\n    def __init__(self, aggr_type=[], p=[], clamp=[], pred_limit=[], bc_dpos=[]):\n        super(GravityModel, self).__init__(aggr='add')  # \"mean\" aggregation.\n\n        self.p = p\n        self.clamp = clamp\n        self.pred_limit = pred_limit\n        self.bc_dpos = bc_dpos\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 5])\n\n        mass = self.p[particle_type]\n        dd_pos = self.propagate(edge_index, pos=x[:, 1:3], mass=mass[:, None])\n        return dd_pos\n\n    def message(self, pos_i, pos_j, mass_j):\n        distance_ij = torch.sqrt(torch.sum(self.bc_dpos(pos_j - pos_i) ** 2, axis=1))\n        distance_ij = torch.clamp(distance_ij, min=self.clamp)\n        direction_ij = self.bc_dpos(pos_j - pos_i) / distance_ij[:, None]\n        dd_pos = mass_j * direction_ij / (distance_ij[:, None] ** 2)\n\n        return torch.clamp(dd_pos, max=self.pred_limit)\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe data is generated with the above Pytorch Geometric model. Note two datasets are generated, one for training and one for validation. If the simulation is too large, you can decrease n_particles (multiple of 16) in “gravity_16.yaml”.\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nmodel = GravityModel(aggr_type=config.graph_model.aggr_type, p=torch.squeeze(p), clamp=config.training.clamp,\n              pred_limit=config.training.pred_limit, bc_dpos=bc_dpos)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\nFinally, we generate the figures shown in Figure 2. All frames are saved in ‘decomp-gnn/paper_experiments/graphs_data/gravity_16/Fig/’.\n\n\n\n\n\nInitial configuration of the simulation. There are 960 particles. The colors indicate different masses.\n\n\n\n\n\n\n\n\n\nFrame 600 out of 2000\n\n\n\n\n\n\n\n\n\nFrame 1200 out of 2000\n\n\n\n\n\n\n\n\n\nFrame 1800 out of 2000"
  },
  {
    "objectID": "paper_experiments/create_fig_wave.html",
    "href": "paper_experiments/create_fig_wave.html",
    "title": "Training GNN on wave propagation",
    "section": "",
    "text": "This script generates Supplementary Figure 15. It demonstrates how a Graph Neural Network (GNN) learns the rules of wave propagation. The training simulation consists of 1E4 mesh observed over 8E3 frames. Nodes interact via wave propagation with type-dependent coefficients.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'wave_slit'\nfigure_id = 'supp15'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the wave-propagation model with PyTorch Geometric.\n\nclass WaveModel(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the Laplacian of a scalar field.\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n    note the Laplacian coeeficients are in data.edge_attr\n\n    Returns\n    -------\n    laplacian : float\n        the Laplacian\n    \"\"\"\n\n    def __init__(self, aggr_type=[], beta=[], bc_dpos=[], coeff=[]):\n        super(WaveModel, self).__init__(aggr='add')  # \"mean\" aggregation.\n\n        self.beta = beta\n        self.bc_dpos = bc_dpos\n        self.coeff = coeff\n\n    def forward(self, data):\n        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n\n        c = self.coeff\n        u = x[:, 6:7]\n\n        laplacian_u = self.propagate(edge_index, u=u, edge_attr=edge_attr)\n        dd_u = self.beta * c * laplacian_u\n\n        self.laplacian_u = laplacian_u\n\n        return dd_u\n\n    def message(self, u_j, edge_attr):\n        L = edge_attr[:,None] * u_j\n\n        return L\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe coefficients of diffusion are loaded from a tif file specified in the config yaml file and the data is generated.\nVizualizations of the wave propagation can be found in “decomp-gnn/paper_experiments/graphs_data/graphs_wave_slit/”\nIf the simulation is too large, you can decrease n_particles and n_nodes in “wave_slit.yaml”.\n\nmodel = WaveModel(aggr_type=config.graph_model.aggr_type, beta=config.simulation.beta)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', erase=False, save=True, step=50)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=20)\n\ndata_generate_mesh(config, model , **generate_kwargs)\n\n\n\n\n\n\nInitial configuration of the simulation. There are 1E4 nodes. The colors indicate the node scalar values.\n\n\n\n\n\n\n\n\n\nFrame 7500 out of 8000\n\n\n\n\nThe GNN model (see src/ParticleGraph/models/Mesh_Laplacian.py) is optimized using the simulated data.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nThe model that has been trained in the previous step is used to generate the rollouts.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate the figures that are shown in Supplementary Figure 15. The results of the GNN post-analysis are saved into ‘decomp-gnn/paper_experiments/log/try_wave_slit/results’.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nLearned latent vectors (x1E4)\n\n\n\n\n\n\n\n\n\nLearned interaction functions (x1E4)\n\n\n\n\n\n\n\n\n\nLearned map of the wave propagation coefficients\n\n\n\n\n\n\n\n\n\nGNN rollout inference at frame 7980\n\n\n\n\nAll frames can be found in “decomp-gnn/paper_experiments/log/try_wave_slit/tmp_recons/”"
  },
  {
    "objectID": "paper_experiments/create_fig_2_4.html",
    "href": "paper_experiments/create_fig_2_4.html",
    "title": "Boids system with 16 different particle types",
    "section": "",
    "text": "This script creates the fourth column of paper’s Figure 2. Simulation of boids (https://en.wikipedia.org/wiki/Boids), 1792 particles, 16 types.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'boids_16_256'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the boids system with PyTorch Geometric.\n\nclass BoidsModel(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the acceleration of Boids as a function of their relative positions and relative positions.\n    The interaction function is defined by three parameters p = (p1, p2, p3)\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n\n    Returns\n    -------\n    pred : float\n        the acceleration of the Boids (dimension 2)\n    \"\"\"\n\n    def __init__(self, aggr_type=[], p=[], bc_dpos=[], dimension=2):\n        super(BoidsModel, self).__init__(aggr=aggr_type)  # \"mean\" aggregation.\n\n        self.p = p\n        self.bc_dpos = bc_dpos\n        self.dimension = dimension\n\n        self.a1 = 0.5E-5\n        self.a2 = 5E-4\n        self.a3 = 1E-8\n        self.a4 = 0.5E-5\n        self.a5 = 1E-8\n\n    def forward(self, data=[], has_field=False):\n        x, edge_index = data.x, data.edge_index\n\n        if has_field:\n            field = x[:,6:7]\n        else:\n            field = torch.ones_like(x[:,0:1])\n\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 1 + 2*self.dimension])\n        parameters = self.p[particle_type, :]\n        d_pos = x[:, self.dimension+1:1 + 2*self.dimension].clone().detach()\n        dd_pos = self.propagate(edge_index, pos=x[:, 1:self.dimension+1], parameters=parameters, d_pos=d_pos, field=field)\n\n        return dd_pos\n\n    def message(self, pos_i, pos_j, parameters_i, d_pos_i, d_pos_j, field_j):\n        distance_squared = torch.sum(self.bc_dpos(pos_j - pos_i) ** 2, axis=1)  # distance squared\n\n        cohesion = parameters_i[:,0,None] * self.a1 * self.bc_dpos(pos_j - pos_i)\n        alignment = parameters_i[:,1,None] * self.a2 * self.bc_dpos(d_pos_j - d_pos_i)\n        separation = - parameters_i[:,2,None] * self.a3 * self.bc_dpos(pos_j - pos_i) / distance_squared[:, None]\n\n        return (separation + alignment + cohesion) * field_j\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe data is generated with the above Pytorch Geometric model. Note two datasets are generated, one for training and one for validation.\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nmodel = BoidsModel(aggr_type=config.graph_model.aggr_type, p=torch.squeeze(p), bc_dpos=bc_dpos, dimension=config.simulation.dimension)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\nFinally, we generate the figures that are shown in Figure 2. All frames are saved in ‘decomp-gnn/paper_experiments/graphs_data/graphs_boids_16_256/Fig/’.\n\n\n\n\n\nInitial configuration of the simulation. There are 1792 boids. The colors indicate different types.\n\n\n\n\n\n\n\n\n\nFrame 2500 out of 8000\n\n\n\n\n\n\n\n\n\nFrame 5000 out of 8000\n\n\n\n\n\n\n\n\n\nFrame 7500 out of 8000"
  },
  {
    "objectID": "paper_experiments/create_fig_2_1.html",
    "href": "paper_experiments/create_fig_2_1.html",
    "title": "Attraction-repulsion system with 3 particle types",
    "section": "",
    "text": "This script creates the first column of paper’s Figure 2. Simulation of an attraction-repulsion system, 4800 particles, 3 particle types.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'arbitrary_3'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the attraction-repulsion system with PyTorch Geometric.\n\nclass AttractionRepulsionModel(pyg.nn.MessagePassing):\n    \"\"\"\n    Compute the speed of particles as a function of their relative position according to an attraction-repulsion law.\n    The latter is defined by four parameters p = (p1, p2, p3, p4) and a parameter sigma.\n\n    See https://github.com/gpeyre/numerical-tours/blob/master/python/ml_10_particle_system.ipynb\n    \"\"\"\n\n    def __init__(self, p, sigma, bc_dpos, dimension=2):\n        super(AttractionRepulsionModel, self).__init__(aggr='mean')\n\n        self.p = p\n        self.sigma = sigma\n        self.bc_dpos = bc_dpos\n        self.dimension = dimension\n\n    def forward(self, data: Data):\n        x, edge_index = data.x, data.edge_index\n\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 1 + 2 * self.dimension])\n        parameters = self.p[particle_type,:]\n        d_pos = self.propagate(edge_index, pos=x[:, 1:self.dimension + 1], parameters=parameters)\n        return d_pos\n\n    def message(self, pos_i, pos_j, parameters_i):\n\n        relative_position = self.bc_dpos(pos_j - pos_i)\n        distance_squared = torch.sum(relative_position ** 2, dim=1)  # squared distance\n        f = (parameters_i[:, 0] * torch.exp(-distance_squared ** parameters_i[:, 1] / (2 * self.sigma ** 2))\n             - parameters_i[:, 2] * torch.exp(-distance_squared ** parameters_i[:, 3] / (2 * self.sigma ** 2)))\n        velocity = f[:, None] * relative_position\n\n        return velocity\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe data is generated with the above Pytorch Geometric model. Note two datasets are generated, one for training and one for validation. If the simulation is too large, you can decrease n_particles (multiple of 3) in “arbitrary_3.yaml”.\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nsigma = config.simulation.sigma\nmodel = AttractionRepulsionModel(\n    p=p,\n    sigma=sigma,\n    bc_dpos=bc_dpos,\n    dimension=config.simulation.dimension\n)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\nFinally, we generate the figures that are shown in Figure 2. All frames are saved in ‘decomp-gnn/paper_experiments/graphs_data/arbitrary_3/Fig/’.\n\n\n\n\n\nInitial configuration of the simulation. There are 4800 particles. The orange, blue, and green particles represent the three different particle types.\n\n\n\n\n\n\n\n\n\nFrame 80 out 250\n\n\n\n\n\n\n\n\n\nFrame 160 out 250\n\n\n\n\n\n\n\n\n\nFrame 240 out 250"
  },
  {
    "objectID": "paper_experiments/create_fig_3_4.html",
    "href": "paper_experiments/create_fig_3_4.html",
    "title": "Training GNN on attraction-repulsion (16 particle types)",
    "section": "",
    "text": "This script creates the fourth column of Figure 3. A GNN learns the motion rules of an attraction-repulsion system. The simulation used to train the GNN consists of 4800 particles of three different types. The particles interact with each other according to 16 different attraction-repulsion laws.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'arbitrary_16'\nfigure_id = '3_4'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the attraction-repulsion system with PyTorch Geometric.\n\nclass AttractionRepulsionModel(pyg.nn.MessagePassing):\n    \"\"\"\n    Compute the speed of particles as a function of their relative position according to an attraction-repulsion law.\n    The latter is defined by four parameters p = (p1, p2, p3, p4) and a parameter sigma.\n\n    See https://github.com/gpeyre/numerical-tours/blob/master/python/ml_10_particle_system.ipynb\n    \"\"\"\n\n    def __init__(self, p, sigma, bc_dpos, dimension=2):\n        super(AttractionRepulsionModel, self).__init__(aggr='mean')\n\n        self.p = p\n        self.sigma = sigma\n        self.bc_dpos = bc_dpos\n        self.dimension = dimension\n\n    def forward(self, data: Data):\n        x, edge_index = data.x, data.edge_index\n\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 1 + 2 * self.dimension])\n        parameters = self.p[particle_type,:]\n        d_pos = self.propagate(edge_index, pos=x[:, 1:self.dimension + 1], parameters=parameters)\n        return d_pos\n\n\n    def message(self, pos_i, pos_j, parameters_i):\n\n        relative_position = self.bc_dpos(pos_j - pos_i)\n        distance_squared = torch.sum(relative_position ** 2, dim=1)  # squared distance\n        f = (parameters_i[:, 0] * torch.exp(-distance_squared ** parameters_i[:, 1] / (2 * self.sigma ** 2))\n             - parameters_i[:, 2] * torch.exp(-distance_squared ** parameters_i[:, 3] / (2 * self.sigma ** 2)))\n        velocity = f[:, None] * relative_position\n\n        return velocity\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe training data is generated with the above Pytorch Geometric model\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nsigma = config.simulation.sigma\nmodel = AttractionRepulsionModel(\n    p=p,\n    sigma=sigma,\n    bc_dpos=bc_dpos,\n    dimension=config.simulation.dimension\n)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\nThe GNN model (see src/ParticleGraph/models/Interaction_Particle.py) is trained and tested.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nThe model that has been trained in the previous step is used to generate the rollouts. The rollout visualization can be found in paper_experiments/log/try_arbitrary_16/tmp_recons.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate the figures that are shown in Figure 3.\n\n\nlog_dir: ./log/try_arbitrary_16\nGNN trained with simulation PDE_A (16 types), with cluster method: distance_plot   threshold: 0.01\nload data ...\nvnorm:2.39e-03,  ynorm:2.40e-03\nnetwork: ./log/try_arbitrary_16/models/best_model_with_1_graphs_20.pt\ninteraction functions ...\nUMAP reduction ...\ndone ...\nClustering computation time is 0.1858987808227539 seconds.\n0.9997916666666666 16\nresult accuracy: 1.0    n_clusters: 16    obtained with  method: distance_plot   threshold: 0.01\ninteraction functions ...\nUMAP reduction ...\ndone ...\nClustering computation time is 0.20686697959899902 seconds.\n0.9991666666666666 20\nresult accuracy: 1.0    n_clusters: 20    obtained with  method: distance_embedding   threshold: 0.01\nall function RMS error: 9.2e-04+/-8.2e-04\n \n \n \n \n\n\n\n\n\n\n\nInitial configuration of the test training dataset. There are 4800 particles. Colors indicate the particle types.\n\n\n\n\n\n\n\n\n\nFinal configuration at frame 500\n\n\n\n\n\n\n\n\n\nLearned latent vectors (x4800)\n\n\n\n\n\n\n\n\n\nLearned interaction functions (x16)\n\n\n\n\n\n\n\n\n\nGNN rollout inference at frame 500"
  },
  {
    "objectID": "paper_experiments/create_fig_gravity.html",
    "href": "paper_experiments/create_fig_gravity.html",
    "title": "Training GNN on gravity-like system",
    "section": "",
    "text": "This script generates Supplementary Figure 7. A GNN learns the motion rules governing a gravity-like system The simulation used to train the GNN consists of 960 particles of 16 different masses. The particles interact with each other according to gravity law.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'gravity_16'\nfigure_id = 'supp7'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the gravity-like system with PyTorch Geometric.\n\nclass GravityModel(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the acceleration of particles as a function of their relative position according to the gravity law.\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n\n    Returns\n    -------\n    pred : float\n        the acceleration of the particles (dimension 2)\n    \"\"\"\n\n    def __init__(self, aggr_type=[], p=[], clamp=[], pred_limit=[], bc_dpos=[]):\n        super(GravityModel, self).__init__(aggr='add')  # \"mean\" aggregation.\n\n        self.p = p\n        self.clamp = clamp\n        self.pred_limit = pred_limit\n        self.bc_dpos = bc_dpos\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 5])\n\n        mass = self.p[particle_type]\n        dd_pos = self.propagate(edge_index, pos=x[:, 1:3], mass=mass[:, None])\n        return dd_pos\n\n    def message(self, pos_i, pos_j, mass_j):\n        distance_ij = torch.sqrt(torch.sum(self.bc_dpos(pos_j - pos_i) ** 2, axis=1))\n        distance_ij = torch.clamp(distance_ij, min=self.clamp)\n        direction_ij = self.bc_dpos(pos_j - pos_i) / distance_ij[:, None]\n        dd_pos = mass_j * direction_ij / (distance_ij[:, None] ** 2)\n\n        return torch.clamp(dd_pos, max=self.pred_limit)\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe training data is generated with the above Pytorch Geometric model\nVizualizations of the particle motions can be found in “decomp-gnn/paper_experiments/graphs_data/gravity_16/”\nIf the simulation is too large, you can decrease n_particles (multiple of 16) in “gravity_16.yaml”\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nmodel = GravityModel(aggr_type=config.graph_model.aggr_type, p=torch.squeeze(p), clamp=config.training.clamp,\n              pred_limit=config.training.pred_limit, bc_dpos=bc_dpos)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=20, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\n\n\n\n\n\nInitial configuration of the simulation. There are 960 particles. The colors indicate different masses.\n\n\n\n\n\n\n\n\n\nFrame 1800 out of 2000\n\n\n\n\nThe GNN model (see src/ParticleGraph/models/Interaction_Particle.py) is trained and tested.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nDuring training the embedding is saved in “paper_experiments/log/try_gravity_16/tmp_training/embedding” The plot of the pairwise interactions is saved in “paper_experiments/log/try_gravity_16/tmp_training/function”\nThe model that has been trained in the previous step is used to generate the rollouts.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate the figures that are shown in Supplementary Figure 7. The results of the GNN post-analysis are saved into ‘decomp-gnn/paper_experiments/log/try_gravity_16/results’.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nLearned latent vectors (x960)\n\n\n\n\n\n\n\n\n\nLearned interaction functions (x16)\n\n\n\n\n\n\n\n\n\nLearned masses (x16)\n\n\n\n\n\n\n\n\n\nGNN rollout inference at frame 1980\n\n\n\n\nAll frames can be found in “decomp-gnn/paper_experiments/log/try_gravity_16/tmp_recons/”"
  },
  {
    "objectID": "paper_experiments/create_fig_4.html",
    "href": "paper_experiments/create_fig_4.html",
    "title": "Training GNN on attraction-repulsion (hidden field)",
    "section": "",
    "text": "This script creates figure of paper’s Figure 4. A GNN learns the motion rules of an attraction-repulsion system. The simulation used to train the GNN consists of 4800 particles of three different types. The particles interact with each other according to three different attraction-repulsion laws. The particle interact also with a hidden dynamical field.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'arbitrary_3_field_video'\nfigure_id = '4'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the attraction-repulsion system with PyTorch Geometric.\n\nclass ParticleField(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the speed of particles as a function of their relative position according to an attraction-repulsion law.\n    The latter is defined by four parameters p = (p1, p2, p3, p4) and a parameter sigma.\n\n    See https://github.com/gpeyre/numerical-tours/blob/master/python/ml_10_particle_system.ipynb\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n\n    Returns\n    -------\n    pred : float\n        the speed of the particles (dimension 2)\n    \"\"\"\n\n    def __init__(self, aggr_type=[], p=[], sigma=[], bc_dpos=[], dimension=2):\n        super(ParticleField, self).__init__(aggr=aggr_type)  # \"mean\" aggregation.\n\n        self.p = p\n        self.sigma = sigma\n        self.bc_dpos = bc_dpos\n        self.dimension = dimension\n\n    def forward(self, data=[], has_field=False):\n        x, edge_index = data.x, data.edge_index\n\n        if has_field:\n            field = x[:,6:7]\n        else:\n            field = torch.ones_like(x[:,0:1])\n\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 1 + 2*self.dimension])\n        parameters = self.p[particle_type,:]\n        d_pos = self.propagate(edge_index, pos=x[:, 1:self.dimension+1], parameters=parameters, field=field)\n        return d_pos\n\n    def message(self, pos_i, pos_j, parameters_i, field_j):\n\n        distance_squared = torch.sum(self.bc_dpos(pos_j - pos_i) ** 2, axis=1)  # squared distance\n        f = (parameters_i[:, 0] * torch.exp(-distance_squared ** parameters_i[:, 1] / (2 * self.sigma ** 2))\n               - parameters_i[:, 2] * torch.exp(-distance_squared ** parameters_i[:, 3] / (2 * self.sigma ** 2)))\n        d_pos = f[:, None] * self.bc_dpos(pos_j - pos_i) * field_j\n\n        return d_pos\n\n    def psi(self, r, p):\n        return r * (p[0] * torch.exp(-r ** (2 * p[1]) / (2 * self.sigma ** 2))\n                    - p[2] * torch.exp(-r ** (2 * p[3]) / (2 * self.sigma ** 2)))\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe training data is generated with the above Pytorch Geometric model\nVizualizations of the particle motions can be found in “decomp-gnn/paper_experiments/graphs_data/graphs_arbitrary_3_field_video/”\nIf the simulation is too large, you can decrease n_particles (multiple of 3) and n_nodes in “arbitrary_3_field_video.yaml”\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nsigma = config.simulation.sigma\nmodel = ParticleField(\n    aggr_type=config.graph_model.aggr_type,\n    p=p,\n    sigma=sigma,\n    bc_dpos=bc_dpos,\n    dimension=config.simulation.dimension\n)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=20)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=20, save_velocity=True)\n\ndata_generate_particle_field(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\n\n\n\n\n\nFrame 100. The orange, blue, and green particles represent the three different particle types.\n\n\n\n\n\n\n\n\n\nFrame 100. The arrows shows the influence of the hidden field on the particles velocity field.\n\n\n\n\nThe GNN model (see src/ParticleGraph/models/Interaction_Particle.py) is trained and tested.\nSince we ship the trained model with the repository, this step can be skipped if desired.\nDuring training the plots of the embedding are saved in “paper_experiments/log/try_arbitrary_3_field_video/tmp_training/embedding”. The plots of the interaction functions are saved in “function” and the hidden field in “field”.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nThe model that has been trained in the previous step is used to generate the rollouts.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate the figures that are shown in Figure 4. The results of the GNN post-analysis are saved into ‘decomp-gnn/paper_experiments/log/try_arbitrary_3_field_video/results’.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nLearned latent vectors (x4800)\n\n\n\n\n\n\n\n\n\nLearned interaction functions (x3)\n\n\n\n\n\n\n\n\n\nUMAP projection of the learned interaction functions (x3)\n\n\n\n\n\n\n\n\n\nGNN rollout inference at frame 100\n\n\n\n\n\n\n\n\n\nReconstructed field at frame 100\n\n\n\n\n\n\n\n\n\nComparison betwween true and learned hidden field values\n\n\n\n\nAll frames can be found in “decomp-gnn/paper_experiments/log/try_arbitrary_3_field_video/tmp_recons/”"
  },
  {
    "objectID": "paper_experiments/create_fig_3_1.html",
    "href": "paper_experiments/create_fig_3_1.html",
    "title": "Training GNN on attraction-repulsion (3 particle types)",
    "section": "",
    "text": "This script creates the first column of paper’s Figure 3. A GNN learns the motion rules of an attraction-repulsion system. The simulation used to train the GNN consists of 4800 particles of three different types. The particles interact with each other according to three different attraction-repulsion laws.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'arbitrary_3'\nfigure_id = '3_1'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the attraction-repulsion system with PyTorch Geometric.\n\nclass AttractionRepulsionModel(pyg.nn.MessagePassing):\n    \"\"\"\n    Compute the speed of particles as a function of their relative position according to an attraction-repulsion law.\n    The latter is defined by four parameters p = (p1, p2, p3, p4) and a parameter sigma.\n\n    See https://github.com/gpeyre/numerical-tours/blob/master/python/ml_10_particle_system.ipynb\n    \"\"\"\n\n    def __init__(self, p, sigma, bc_dpos, dimension=2):\n        super(AttractionRepulsionModel, self).__init__(aggr='mean')\n\n        self.p = p\n        self.sigma = sigma\n        self.bc_dpos = bc_dpos\n        self.dimension = dimension\n\n    def forward(self, data: Data):\n        x, edge_index = data.x, data.edge_index\n\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 1 + 2 * self.dimension])\n        parameters = self.p[particle_type,:]\n        d_pos = self.propagate(edge_index, pos=x[:, 1:self.dimension + 1], parameters=parameters)\n        return d_pos\n\n\n    def message(self, pos_i, pos_j, parameters_i):\n\n        relative_position = self.bc_dpos(pos_j - pos_i)\n        distance_squared = torch.sum(relative_position ** 2, dim=1)  # squared distance\n        f = (parameters_i[:, 0] * torch.exp(-distance_squared ** parameters_i[:, 1] / (2 * self.sigma ** 2))\n             - parameters_i[:, 2] * torch.exp(-distance_squared ** parameters_i[:, 3] / (2 * self.sigma ** 2)))\n        velocity = f[:, None] * relative_position\n\n        return velocity\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe training data is generated with the above Pytorch Geometric model\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nsigma = config.simulation.sigma\nmodel = AttractionRepulsionModel(\n    p=p,\n    sigma=sigma,\n    bc_dpos=bc_dpos,\n    dimension=config.simulation.dimension\n)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\nThe GNN model (see src/ParticleGraph/models/Interaction_Particle.py) is trained and tested.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nThe model that has been trained in the previous step is used to generate the rollouts. The rollout visualization can be found in paper_experiments/log/try_arbitrary_3/tmp_recons.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate the figures that are shown in Figure 3.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nInitial configuration of the test training dataset. There are 4800 particles. The orange, blue, and green particles represent the three different particle types.\n\n\n\n\n\n\n\n\n\nFinal configuration at frame 250\n\n\n\n\n\n\n\n\n\nLearned latent vectors (x4800)\n\n\n\n\n\n\n\n\n\nLearned interaction functions (x3)\n\n\n\n\n\n\n\n\n\nGNN rollout inference at frame 250"
  },
  {
    "objectID": "paper_experiments/create_fig_3_6.html",
    "href": "paper_experiments/create_fig_3_6.html",
    "title": "Training GNN on attraction-repulsion (64 particle types)",
    "section": "",
    "text": "This script creates the sixth column of paper’s Figure 3. A GNN learns the motion rules of an attraction-repulsion system. The simulation used to train the GNN consists of 4800 particles of 64 different types. The particles interact with each other according to three different attraction-repulsion laws.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'arbitrary_64'\nfigure_id = '3_6'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the attraction-repulsion system with PyTorch Geometric.\n\nclass AttractionRepulsionModel(pyg.nn.MessagePassing):\n    \"\"\"\n    Compute the speed of particles as a function of their relative position according to an attraction-repulsion law.\n    The latter is defined by four parameters p = (p1, p2, p3, p4) and a parameter sigma.\n\n    See https://github.com/gpeyre/numerical-tours/blob/master/python/ml_10_particle_system.ipynb\n    \"\"\"\n\n    def __init__(self, p, sigma, bc_dpos, dimension=2):\n        super(AttractionRepulsionModel, self).__init__(aggr='mean')\n\n        self.p = p\n        self.sigma = sigma\n        self.bc_dpos = bc_dpos\n        self.dimension = dimension\n\n    def forward(self, data: Data):\n        x, edge_index = data.x, data.edge_index\n\n        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n        particle_type = to_numpy(x[:, 1 + 2 * self.dimension])\n        parameters = self.p[particle_type,:]\n        d_pos = self.propagate(edge_index, pos=x[:, 1:self.dimension + 1], parameters=parameters)\n        return d_pos\n\n\n    def message(self, pos_i, pos_j, parameters_i):\n\n        relative_position = self.bc_dpos(pos_j - pos_i)\n        distance_squared = torch.sum(relative_position ** 2, dim=1)  # squared distance\n        f = (parameters_i[:, 0] * torch.exp(-distance_squared ** parameters_i[:, 1] / (2 * self.sigma ** 2))\n             - parameters_i[:, 2] * torch.exp(-distance_squared ** parameters_i[:, 3] / (2 * self.sigma ** 2)))\n        velocity = f[:, None] * relative_position\n\n        return velocity\n\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe training data is generated with the above Pytorch Geometric model.\n\np = torch.squeeze(torch.tensor(config.simulation.params))\nsigma = config.simulation.sigma\nmodel = AttractionRepulsionModel(\n    p=p,\n    sigma=sigma,\n    bc_dpos=bc_dpos,\n    dimension=config.simulation.dimension\n)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', alpha=1, erase=True, save=True, step=10)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_particles(config, model, bc_pos, bc_dpos, **generate_kwargs)\n\nThe GNN model (see src/ParticleGraph/models/Interaction_Particle.py) is trained and tested.\nSince we ship the trained model with the repository, this step can be skipped if desired.\n\nif not os.path.exists(f'log/try_{config_file}'):\n    data_train(config, config_file, **train_kwargs)\n\nThe model that has been trained in the previous step is used to generate the rollouts. The rollout visualization can be found in paper_experiments/log/try_arbitrary_64/tmp_recons.\n\ndata_test(config, config_file, **test_kwargs)\n\nFinally, we generate the figures that are shown in Figure 3.\n\nconfig_list, epoch_list = get_figures(figure_id, device=device)\n\n\n\n\n\n\nInitial configuration of the test training dataset. There are 4800 particles. Colors indicate the particle types.\n\n\n\n\n\n\n\n\n\nFinal configuration at frame 1000\n\n\n\n\n\n\n\n\n\nLearned latent vectors (x4800)\n\n\n\n\n\n\n\n\n\nLearned interaction functions (x64)\n\n\n\n\n\n\n\n\n\nInitial random configuration for rollout\n\n\n\n\n\n\n\n\n\nFinal configuration in rollout at frame 1000"
  },
  {
    "objectID": "paper_experiments/create_fig_2_5.html",
    "href": "paper_experiments/create_fig_2_5.html",
    "title": "Wave propagation with different diffusion coefficients",
    "section": "",
    "text": "This script creates the fifth column of paper’s Figure 2. Simulation of wave-propagation over a mesh of 1E4 nodes with variable propagation-coefficients.\nFirst, we load the configuration file and set the device.\n\nconfig_file = 'wave_slit'\nconfig = ParticleGraphConfig.from_yaml(f'./config/{config_file}.yaml')\ndevice = set_device(\"auto\")\n\nThe following model is used to simulate the wave propagation with PyTorch Geometric.\n\nclass WaveModel(pyg.nn.MessagePassing):\n    \"\"\"Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n\n    \"\"\"\n    Compute the Laplacian of a scalar field.\n\n    Inputs\n    ----------\n    data : a torch_geometric.data object\n    note the Laplacian coeeficients are in data.edge_attr\n\n    Returns\n    -------\n    laplacian : float\n        the Laplacian\n    \"\"\"\n\n    def __init__(self, aggr_type=[], beta=[], bc_dpos=[], coeff=[]):\n        super(WaveModel, self).__init__(aggr='add')  # \"mean\" aggregation.\n\n        self.beta = beta\n        self.bc_dpos = bc_dpos\n        self.coeff = coeff\n\n    def forward(self, data):\n        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n\n        c = self.coeff\n        u = x[:, 6:7]\n\n        laplacian_u = self.propagate(edge_index, u=u, edge_attr=edge_attr)\n        dd_u = self.beta * c * laplacian_u\n\n        self.laplacian_u = laplacian_u\n\n        return dd_u\n\n    def message(self, u_j, edge_attr):\n        L = edge_attr[:,None] * u_j\n\n        return L\n\ndef bc_pos(x):\n    return torch.remainder(x, 1.0)\n\ndef bc_dpos(x):\n    return torch.remainder(x - 0.5, 1.0) - 0.5\n\nThe data is generated with the above Pytorch Geometric model. Note two datasets are generated, one for training and one for validation. If the simulation is too large, you can decrease n_particles (multiple of 5) and n_nodes in “wave_slit.yaml”\n\nmodel = WaveModel(aggr_type=config.graph_model.aggr_type, beta=config.simulation.beta)\n\ngenerate_kwargs = dict(device=device, visualize=True, run_vizualized=0, style='color', erase=False, save=True, step=20)\ntrain_kwargs = dict(device=device, erase=True)\ntest_kwargs = dict(device=device, visualize=True, style='color', verbose=False, best_model='20', run=0, step=1, save_velocity=True)\n\ndata_generate_mesh(config, model , **generate_kwargs)\n\nFinally, we generate the figures that are shown in Figure 2. All frames are saved in ‘decomp-gnn/paper_experiments/graphs_data/graphs_wave_slit/Fig/’.\n\n\n\n\n\nInitial configuration of the simulation. There are 1E4 nodes. The colors indicate the node scalar values.\n\n\n\n\n\n\n\n\n\nFrame 2500 out of 8000\n\n\n\n\n\n\n\n\n\nFrame 5000 out of 8000\n\n\n\n\n\n\n\n\n\nFrame 7500 out of 8000"
  }
]